"""
The 77 core PyTorch operators that appear in TorchBench traces.
These are the high-priority operations for KernelAgent's first release.
"""

CORE_TORCHBENCH_OPS = [
    "abs",
    "_adaptive_avg_pool2d",
    "_adaptive_avg_pool2d_backward",
    "add",
    "addmm",
    "any",
    "avg_pool2d",
    "avg_pool2d_backward",
    "bitwise_and",
    "bitwise_not",
    "bitwise_xor",
    "bmm",
    "cat",
    "clamp",
    "clone",
    "col2im",
    "constant_pad_nd",
    "convolution",
    "convolution_backward",
    "cos",
    "cumsum",
    "div",
    "elu",
    "eq",
    "erf",
    "exp",
    "flip",
    "floor",
    "fmod",
    "ge",
    "gelu",
    "grid_sampler_2d",
    "gt",
    "hardtanh",
    "isinf",
    "isnan",
    "le",
    "leaky_relu",
    "log2",
    "_log_softmax",
    "lt",
    "max",
    "maximum",
    "max_pool2d_with_indices",
    "max_pool2d_with_indices_backward",
    "mean",
    "min",
    "minimum",
    "mm",
    "mul",
    "native_group_norm",
    "native_group_norm_backward",
    "native_layer_norm",
    "ne",
    "neg",
    "nonzero",
    "pow",
    "reciprocal",
    "reflection_pad2d",
    "relu",
    "remainder",
    "repeat",
    "round",
    "rsqrt",
    "sigmoid",
    "sin",
    "_softmax",
    "split_with_sizes",
    "sqrt",
    "sub",
    "sum",
    "tanh",
    "_to_copy",
    "topk",
    "upsample_bilinear2d",
    "upsample_nearest2d",
    "where",
]

# Some of these ops might have variants or different names in the actual op registry
# This mapping helps handle common variations
OP_NAME_VARIATIONS = {
    "_adaptive_avg_pool2d": ["adaptive_avg_pool2d"],
    "_adaptive_avg_pool2d_backward": ["adaptive_avg_pool2d_backward"],
    "_log_softmax": ["log_softmax"],
    "_softmax": ["softmax"],
    "_to_copy": ["to_copy", "to"],
}