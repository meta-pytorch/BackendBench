[
  {
    "op_name": "_log_softmax_backward_data.default",
    "args": "((T([8192, 50265], f16), T([8192, 50265], f16), 1, torch.float16,), {})",
    "error": ""
  },
  {
    "op_name": "constant_pad_nd.default",
    "args": "((T([128, 96, 113, 113], f16), [0, -1, 0, -1],), {})",
    "error": "'list' object is not callable"
  },
  {
    "op_name": "cumsum.default",
    "args": "((T([64, 128], i32), 1,), {})",
    "error": ""
  },
  {
    "op_name": "eq.Tensor",
    "args": "((T([4, 12, 128, 128], f16), T([], f32),), {})",
    "error": ""
  },
  {
    "op_name": "mean.default",
    "args": "((T([6, 3, 352, 352], f16),), {})",
    "error": ""
  },
  {
    "op_name": "minimum.default",
    "args": "((T([2, 1, 1, 448], f16), T([2, 12, 64, 448], f32),), {})",
    "error": ""
  },
  {
    "op_name": "native_batch_norm.default",
    "args": "((T([128, 64, 147, 147], f16), T([64], f16), T([64], f16), T([64], f16), T([64], f16), True, 0.1, 0.001,), {})",
    "error": ""
  },
  {
    "op_name": "native_batch_norm_backward.default",
    "args": "((T([128, 64, 147, 147], f16), T([128, 64, 147, 147], f16), T([64], f16), T([64], f16), T([64], f16), T([64], f32), T([64], f32), True, 0.001, [True, True, True],), {})",
    "error": ""
  },
  {
    "op_name": "native_layer_norm.default",
    "args": "((T([64, 56, 56, 256], f16), [256], T([256], f16), T([256], f16), 1e-06,), {})",
    "error": ""
  },
  {
    "op_name": "topk.default",
    "args": "((T([1, 6905250], f16), 5000, 1,), {})",
    "error": "at 18:11:\n    k: tl.constexpr,\n    N: tl.constexpr,\n    BLOCK_SIZE: tl.constexpr,\n    DESCENDING: tl.constexpr,\n):\n    cur_batch = tle.program_id(0)\n    chunk_x += cur_batch * N\n    chunk_index += cur_batch * N\n    y_ptr += cur_batch * k\n    index_ptr += cur_batch * k\n\n    cols = tl.arange(0, BLOCK_SIZE)\n           ^"
  }
]