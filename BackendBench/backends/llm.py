import importlib.util
import logging
import os
from typing import Callable, Dict, List

from .base import Backend

logger = logging.getLogger(__name__)


class LLMBackend(Backend):
    def __init__(self) -> None:
        super().__init__("llm")
        self.compiled_kernels: Dict[str, Callable] = {}

        # Create generated_kernels directory
        import datetime

        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        self.kernels_dir = f"generated_kernels/run_{timestamp}"
        os.makedirs(self.kernels_dir, exist_ok=True)

        # Create README for this run
        readme_path = os.path.join(self.kernels_dir, "README.md")
        with open(readme_path, "w") as f:
            f.write(
                f"""# Generated Kernels - {timestamp}

This directory contains PyTorch/Triton kernels generated by the LLM Backend.

## Run Info
- Timestamp: {timestamp}
- Backend: LLM

## Files
Each `<op_name>_kernel.py` file contains the complete generated kernel code for that operation, including:
- All necessary imports
- Triton kernel implementation (if applicable)
- Wrapper function that matches PyTorch operation signature

## Usage
You can inspect these files to debug kernel generation, manually test implementations, or understand what the LLM produced.
"""
            )

        print(f"Saving generated kernels to: {self.kernels_dir}")

    def compile_kernel_from_string(
        self, kernel_code: str, op_name: str, attempt: int = 1
    ) -> Callable:
        """Compile a kernel from string code and return a callable."""
        try:
            is_triton = "triton.jit" in kernel_code or "@triton.jit" in kernel_code

            if is_triton:
                full_code = self._prepare_triton_code(kernel_code)
            else:
                full_code = self._prepare_torch_code(kernel_code)

            kernel_file = os.path.join(self.kernels_dir, f"{op_name}_kernel_attempt_{attempt}.py")
            with open(kernel_file, "w") as f:
                f.write(full_code)

            print(f"Saved kernel to: {kernel_file}")

            spec = importlib.util.spec_from_file_location(f"kernel_{op_name}", kernel_file)
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)

            kernel_func = self._find_kernel_function(module, op_name)

            return kernel_func

        except Exception as e:
            raise RuntimeError(f"Failed to compile kernel for {op_name}: {str(e)}")

    def _prepare_triton_code(self, kernel_code: str) -> str:
        """Prepare Triton kernel code with necessary imports."""
        imports = """
import torch
import triton
import triton.language as tl
"""
        if "import torch" not in kernel_code:
            kernel_code = imports + kernel_code
        return kernel_code

    def _prepare_torch_code(self, kernel_code: str) -> str:
        """Prepare regular PyTorch kernel code with necessary imports."""
        imports = """
import torch
import torch.nn.functional as F
"""
        if "import torch" not in kernel_code:
            kernel_code = imports + kernel_code
        return kernel_code

    def _find_kernel_function(self, module, op_name: str) -> Callable:
        """Find the main kernel function in the compiled module."""
        expected_name = f"{op_name}_kernel_impl"

        if hasattr(module, expected_name):
            return getattr(module, expected_name)

        available_functions = [
            name
            for name in dir(module)
            if callable(getattr(module, name)) and not name.startswith("_")
        ]

        raise ValueError(
            f"Expected function '{expected_name}' not found in kernel code for {op_name}. "
            f"Available functions: {available_functions}. "
            f"Please ensure the LLM generated code follows the naming convention: {op_name}_kernel_impl"
        )

    def add_kernel(self, op, kernel_code: str, op_name: str):
        """Add a kernel implementation for a specific operator."""
        compiled_kernel = self.compile_kernel_from_string(kernel_code, op_name, attempt=1)
        self.compiled_kernels[op] = compiled_kernel

    def test_kernel_correctness(
        self, op, kernel_code: str, test_cases: List, attempt: int = 1
    ) -> tuple[bool, Dict]:
        """Test kernel correctness and return detailed feedback."""
        op_str = str(op)
        if "aten." in op_str:
            op_name = op_str.split("aten.")[-1].split(".")[0]
        else:
            op_name = op_str.split(".")[-1]

        feedback_info = {
            "compilation_error": None,
            "test_errors": [],
            "summary": None,
        }

        try:
            kernel_file = os.path.join(self.kernels_dir, f"{op_name}_kernel_attempt_{attempt}.py")

            if not os.path.exists(kernel_file):
                is_triton = "triton.jit" in kernel_code or "@triton.jit" in kernel_code
                if is_triton:
                    full_code = self._prepare_triton_code(kernel_code)
                else:
                    full_code = self._prepare_torch_code(kernel_code)

                with open(kernel_file, "w") as f:
                    f.write(full_code)
                print(f"Saved kernel to: {kernel_file}")

            import importlib.util
            import sys

            spec = importlib.util.spec_from_file_location(
                f"test_kernel_{op_name}_{attempt}", kernel_file
            )
            module = importlib.util.module_from_spec(spec)

            # Add to sys.modules so triton can find it
            sys.modules[f"test_kernel_{op_name}_{attempt}"] = module

            try:
                spec.loader.exec_module(module)

                expected_name = f"{op_name}_kernel_impl"
                if hasattr(module, expected_name):
                    compiled_kernel = getattr(module, expected_name)
                else:
                    available_functions = [
                        name
                        for name in dir(module)
                        if callable(getattr(module, name)) and not name.startswith("_")
                    ]
                    raise ValueError(
                        f"Expected function '{expected_name}' not found. Available: {available_functions}"
                    )

            finally:
                if f"test_kernel_{op_name}_{attempt}" in sys.modules:
                    del sys.modules[f"test_kernel_{op_name}_{attempt}"]

            import torch

            correct_count = 0
            total_count = 0

            for test in test_cases:
                try:
                    args = test.args
                    kwargs = test.kwargs

                    ref_result = op(*args, **kwargs)
                    kernel_result = compiled_kernel(*args, **kwargs)

                    torch.testing.assert_close(ref_result, kernel_result, equal_nan=True)
                    correct_count += 1
                    print(f"    ✓ Test passed: {ref_result.shape} {ref_result.dtype}")

                except Exception as e:
                    import traceback

                    print(f"    ✗ Test failed: {str(e)}")

                    feedback_info["test_errors"].append(
                        {
                            "test_input": f"args={[arg.shape if hasattr(arg, 'shape') else arg for arg in args]}, kwargs={kwargs}",
                            "error": str(e),
                            "error_type": type(e).__name__,
                            "traceback": traceback.format_exc(),
                        }
                    )

                total_count += 1

            is_correct = correct_count == total_count and total_count > 0
            if not is_correct:
                feedback_info["summary"] = f"{correct_count}/{total_count} tests passed"

            return is_correct, feedback_info

        except Exception as e:
            print("    ✗ Compilation failed:")
            print(f"      Error: {str(e)}")

            feedback_info["compilation_error"] = str(e)
            feedback_info["summary"] = "Compilation failed"
            return False, feedback_info

    def __getitem__(self, key):
        if key in self.compiled_kernels:
            return self.compiled_kernels[key]
        raise KeyError(f"No kernel implementation found for {key}")

    def __contains__(self, key):
        return key in self.compiled_kernels
