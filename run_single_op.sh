#!/bin/bash
# Test version - runs only relu operation

# Check if OPENAI_API_KEY is set
if [ -z "$OPENAI_API_KEY" ]; then
    echo "ERROR: Please set OPENAI_API_KEY environment variable"
    exit 1
fi

# Configuration
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
OUTPUT_DIR="generated_kernels/core_ops_run_${TIMESTAMP}"
ORGANIZED_DIR="generated_kernels/organized_${TIMESTAMP}"  # Timestamped to avoid overwriting
LOG_FILE="${OUTPUT_DIR}/run_log.txt"
SUMMARY_FILE="${OUTPUT_DIR}/summary.md"

# Create output directories
mkdir -p "${OUTPUT_DIR}"
mkdir -p "${ORGANIZED_DIR}"

# Test with just relu
CORE_OPS="relu"

echo "Running KernelAgent on relu operator (test run)..."
echo "Output directory: ${OUTPUT_DIR}"
echo ""

# Activate conda environment if needed
if [ -n "$CONDA_PREFIX" ]; then
    PYTHON_CMD="python"
else
    PYTHON_CMD="/home/leyuan/miniconda3/envs/backendbench/bin/python"
fi

# Set Python path
export PYTHONPATH="/home/leyuan/workplace/BackendBench:$PYTHONPATH"

# Run BackendBench with KernelAgent and capture output
echo "Starting kernel generation at $(date)" | tee "${LOG_FILE}"
$PYTHON_CMD BackendBench/scripts/main.py \
    --suite torchbench \
    --backend kernel_agent \
    --ops "$CORE_OPS" \
    --kernel-agent-workers 4 \
    --kernel-agent-max-rounds 5 2>&1 | tee -a "${LOG_FILE}"

echo ""
echo "Kernel generation completed at $(date)" | tee -a "${LOG_FILE}"

# Extract the generated kernels directory from the log
KERNEL_RUN_DIR=$(grep -o "generated_kernels/kernel_agent_run_[0-9_]*" "${LOG_FILE}" | tail -1)

if [ -z "$KERNEL_RUN_DIR" ] || [ ! -d "$KERNEL_RUN_DIR" ]; then
    echo "ERROR: Could not find generated kernels directory"
    exit 1
fi

echo "Found kernels in: $KERNEL_RUN_DIR"

# Check if relu kernel was generated
if [ -f "${KERNEL_RUN_DIR}/relu_kernel.py" ]; then
    echo "✅ Found relu kernel!"
    
    # Extract scores from log FIRST
    CORRECTNESS=$(grep -o "correctness score.*: [0-9.]*" "${LOG_FILE}" | grep -o "[0-9.]*$")
    PERFORMANCE=$(grep -o "performance score.*: [0-9.]*" "${LOG_FILE}" | grep -o "[0-9.]*$")
    
    # Organize the kernel
    mkdir -p "${ORGANIZED_DIR}/relu"
    cp "${KERNEL_RUN_DIR}/relu_kernel.py" "${ORGANIZED_DIR}/relu/relu_implementation_v1.py"
    
    # Create README with scores
    cat > "${ORGANIZED_DIR}/relu/README.md" << EOF
# relu Implementation

## Generation Details
- **Generated by**: KernelAgent
- **Date**: $(date)
- **Source Run**: ${KERNEL_RUN_DIR}

## Performance Results
- **Correctness Score**: ${CORRECTNESS} (passed all BackendBench tests)
- **Performance Score**: ${PERFORMANCE} (vs PyTorch baseline)

## Implementation
This is a Triton kernel implementation that passed all BackendBench correctness tests.
The kernel is in \`relu_implementation_v1.py\`.
EOF

    echo "✅ Organized kernel to: ${ORGANIZED_DIR}/relu/"
    
    # Create a run summary in the organized directory
    cat > "${ORGANIZED_DIR}/RUN_SUMMARY.md" << EOF
# KernelAgent Run Summary - ${TIMESTAMP}

## Configuration
- **Operations tested**: relu
- **Workers**: 4
- **Max rounds**: 5
- **Backend**: kernel_agent

## Results Summary

| Operation | Status | Correctness | Performance | Kernel Location |
|-----------|--------|-------------|-------------|-----------------|
| relu | ✅ Success | ${CORRECTNESS} | ${PERFORMANCE} | relu/relu_implementation_v1.py |

## Usage
To use these kernels with DirectoryBackend:
\`\`\`bash
python BackendBench/scripts/main.py --suite torchbench --backend directory --ops-directory ${ORGANIZED_DIR}
\`\`\`

## Source
Full logs and artifacts: ${OUTPUT_DIR}
EOF
    
    echo ""
    echo "======================================"
    echo "Test Run Results:"
    echo "======================================"
    echo "Operation: relu"
    echo "Status: SUCCESS"
    echo "Correctness Score: ${CORRECTNESS}"
    echo "Performance Score: ${PERFORMANCE}"
    echo "Organized kernels: ${ORGANIZED_DIR}/"
    echo "Run summary: ${ORGANIZED_DIR}/RUN_SUMMARY.md"
    echo ""
else
    echo "❌ relu kernel generation failed"
fi